{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the encoder model\n",
    "encoder = keras.models.Sequential([\n",
    "    #Flatten the iput images (28x28) into a 1D array of 784 el3ments\n",
    "    keras.layers.Flatten(input_shape= [28, 28]),\n",
    "    #Add a dense layer with 100 neurons and ReLU activation function\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    #Add another dense layer with 30 neurons and ReLU acivation function\n",
    "    keras.layers.Dense(30, activation = \"relu\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the decoder model\n",
    "decoder = keras.models.Sequential([\n",
    "    #Add a dense layer with 100 neurons and ReLU activation function, input shape is\n",
    "    keras.layers.Dense(100, activation=\"relu\", input_shape= [30]),\n",
    "    #Add a dense layer with 784 neurons (28*28) and sigmoid activation function function to ......\n",
    "    keras.layers.Dense(28 * 28, activation = \"sigmoid\"),\n",
    "    #Reshape the output into the original image shape (28 x 28)\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_autoencoder = keras.models.Sequential([encoder, decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the stacked autoencoder model \n",
    "stacked_autoencoder.compile(\n",
    "    #Use binary cross_entropy loss function for binary imput data (normalized pixel)\n",
    "    loss = \"binary_crossentropy\",\n",
    "    #Use the Adam optimizer for efficient training\n",
    "    optimizer = 'adam'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the stacked autoencoder model\n",
    "history = stacked_autoencoder.fit(\n",
    "    #Input and target data are both x_train (input images ) for reconstruction\n",
    "    x_train, x_train,\n",
    "    #Train for 10 epochs\n",
    "    epochs = 10,\n",
    "    #Use x_test for validation during training\n",
    "    validation_data = [x_test, x_test]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the figure size for the plot\n",
    "figsize(20, 5)\n",
    "\n",
    "#Iterate over a range of 8 examples from the test set\n",
    "for i in range(8):\n",
    "  #plot the original image from the test set \n",
    "  subplot(2, 8, i+1)\n",
    "  #Make a prediction using the stacked autoencoder on the current test image\n",
    "  pred = stacked_autoencoder.predict(x_test[i].reshape((1, 28, 28)))\n",
    "  # Display the original image\n",
    "  imshow(x_test[i], cmap = \"binary\")\n",
    "  #plot the reconstructed image by the stacked autoencoder\n",
    "  subplot(2, 8, i+8+1)\n",
    "  # Display the reconstructed image\n",
    "  imshow(pred.reshape((28, 28)), cmap = \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(10, 5)\n",
    "# Plot the original image\n",
    "subplot(1, 3, 1)\n",
    "imshow(x_test[i], cmap = \"binary\")\n",
    "\n",
    "# Plot the latent vector representation obtained from the encoder\n",
    "subplot(1, 3, 2)\n",
    "# Predict the latent vector representation of the selected test image\n",
    "latent_vector = encoder.predict(x_test[i].reshape((1, 28, 28)))\n",
    "imshow(latent_vector, cmap = \"binary\")\n",
    "\n",
    "# Plot the reconstructed image from the latent vector using the decoder\n",
    "subplot(1, 3, 3)\n",
    "# Reconstruct the image from the latent vector representation \n",
    "pred = decoder.predict(latent_vector)\n",
    "imshow(pred.reshape((28, 28)), cmap = \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_low = 30 / (28 * 28)  # Upper bound for sparsity constraints\n",
    "#sparsity_high = 1 - sparsity_low  # Lower bound for sparsity constraint\n",
    "sparsity_high = 1 - 30 / (28 * 28)\n",
    "\n",
    "# Print both values\n",
    "print(sparsity_low, sparsity_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoder model using convolutional layers\n",
    "encoder = keras.models.Sequential([\n",
    "    # Reshpe the input into a 28 x 28 x 1 image (grayscale)\n",
    "    keras.layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n",
    "    # First convolutional layer with 16 filters, each of size 3x3, ReLU activation, \n",
    "    keras.layers.Conv2D(16, kernel_size = (3, 3), padding = \"same\", activation= \"relu\"), \n",
    "    # Max pooling layer with pool size 2x2 to dowsample the spatial dimensions\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    # Second convolutional layer with 32 filters, each of size 3x3, ReLU activation\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), padding= \"same\", activation= \"relu\"),\n",
    "    #Max Pooling layer\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    # Third consvolutional layer with 64 filters, each of size 3x3, Relu activation\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    #Max Pooling layer\n",
    "    keras.layers.MaxPool2D(pool_size=2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the decoder model using convolutional transpose layers\n",
    "decoder = keras.models.Sequential([\n",
    "    # Convolutional transpose layer with 32 filters, eacho of size 3x3 stride 2, Relu\n",
    "    keras.layers.Conv2DTranspose(16, kernel_size=(3,3), strides=2, padding=\"valid\", \n",
    "                                 activation=\"relu\", input_shape=[3, 3, 64]),\n",
    "    # Convolutional transpose layer with 16 filters, each of size 3x3, stride 2, ReLU\n",
    "    keras.layers.Conv2DTranspose(16, kernel_size=(3, 3), strides=2, padding=\"same\",\n",
    "                                 activation=\"relu\"),\n",
    "    # Convolutional transpose layer with 1 filter, size 3x3, stride2, sigmoid activat\n",
    "    keras.layers.Conv2DTranspose(1, kernel_size=(3, 3), strides=2, padding=\"same\",\n",
    "                                 activation=\"sigmoid\"),\n",
    "    # Reshape the output into the original image shape (28x28)\n",
    "    keras.layers.Reshape([28, 28])\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the encoder and decoder models to create the stacked autoencoder\n",
    "stacked_autoencoder = keras.models.Sequential([encoder, decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the stacked autoencoder model\n",
    "stacked_autoencoder.compile(\n",
    "    # Use binary cross_entropy loss function for binary input data (normalized Pixel)\n",
    "    loss = \"binary_crossentropy\",\n",
    "    # Use the Adam optimazer for efficient training\n",
    "    optimizer = 'adam'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the stacked autoencoder model on the training data\n",
    "history = stacked_autoencoder.fit(\n",
    "    # Input and target data are both x_train (input images) for reconstruction\n",
    "    x_train, x_train,\n",
    "    # Train for 10 epochs\n",
    "    epochs = 10,\n",
    "    # Use x_test for validation during training\n",
    "    validation_data= [x_test, x_test]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size for the plot\n",
    "figsize(20, 5)\n",
    "\n",
    "# Iterate over 8 examples from the test set\n",
    "for i in range(8):\n",
    "  # plot the original image from the test set\n",
    "  subplot(2, 8, i+1)\n",
    "  # Make a prediction using the stacked autoencoder on the current test image\n",
    "  pred = stacked_autoencoder.predict(x_test[i].reshape((1, 28, 28)))\n",
    "  # Display the original image\n",
    "  imshow(x_test[i], cmap= \"binary\")\n",
    "  # Plot the reconstructed image by the stacked autoencoder\n",
    "  subplot(2, 8, i+8+1)\n",
    "  # Display the reconstructed image\n",
    "  imshow(pred.reshape((28, 28)), cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEt the figure size for the plot\n",
    "figsize(15, 15)\n",
    "\n",
    "# Iterate over all filters in the last convolutional layer of the encoder\n",
    "for i in range(8 * 8):\n",
    "  # Plot each filter as a subplot in an 8x8 grid\n",
    "  subplot(8, 8, i+1)\n",
    "  # Display the weights (filters) of the convolutional layer\n",
    "  imshow (encoder.layers[-2].weights[0][:, :, 0, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Denoising Autoencoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size for the plot\n",
    "figsize(5, 10)\n",
    "\n",
    "# Plot the original image from the test set\n",
    "subplot(1, 2, 1)\n",
    "imshow(x_test[0], cmap=\"binary\")\n",
    "\n",
    "# Plot the noisy version of the original image\n",
    "subplot(1, 2, 2)\n",
    "# GEnerate random noise and add it to the original image\n",
    "noise = np.random.random((28, 28,)) /4\n",
    "imshow(x_test[0] + noise, cmap= \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoder model usin dense (fully connected) layers\n",
    "encoder = keras.models.Sequential([\n",
    "    # Flatten the input images (28x28) into a 1D array of 784 elements\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    # Add a dense layer with 100 neurons and ReLU activation function\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    #Add another dense laher with 100 neurons and ReLU activation \n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    # Add a dense layer with 30 neurons and ReLU activation function\n",
    "    keras.layers.Dense(30, activation=\"relu\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the decoder model using dense (fully connected) layers\n",
    "decoder = keras.models.Sequential([\n",
    "    # Add a dense layer with 100 neurons and ReLu activation function,\n",
    "    keras.layers.Dense(100, activation=\"relu\", input_shape=[30]),\n",
    "    # Add another dense layer with 100 neurons and Relu activation\n",
    "    keras.layers.Dense(100,activation=\"relu\"),\n",
    "    # Add a dense layer with 784 neurons (28* 28) and sigmoid activatation function\n",
    "    keras.layers.Dense(28 * 28, activation='sigmoid'),\n",
    "    # Reshape the output into the original image shape (28x28)\n",
    "    keras.layers.Reshape([28, 28])\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the encoder and decoder models to create the stacked autoencoder\n",
    "stacked_autoencoder = keras.models.Sequential([encoder, decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the stacked autoencoder model\n",
    "stacked_autoencoder.compile(\n",
    "    # Use binary cross_entropy loss function for binary input data (normalized Pixel)\n",
    "    loss = \"binary_crossentropy\",\n",
    "    # Use the Adam optimazer for efficient training\n",
    "    optimizer = 'adam'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add random noise to the training and test data\n",
    "x_train_noise = x_train + ((np.random.random(x_train.shape)) / 4)\n",
    "x_test_noise = x_test + ((np.random.random(x_test.shape)) / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an example of the noisy training data\n",
    "imshow(x_train_noise[0], cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the stacked autoencoder model on the noisy training data\n",
    "history = stacked_autoencoder.fit(\n",
    "    # Input is the noisy training data (x_train_noise), target is the original clean\n",
    "    x_train_noise, x_train,\n",
    "    # Train for 10 epochs\n",
    "    epochs = 10,\n",
    "    # Use noisy test data (x_test_noise) for validation during  during training, with original \n",
    "    validation_data = [x_test_noise, x_test]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
